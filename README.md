# Data Quality Case Study

**Goal:** Automate detection and flagging of data quality issues in company financial datasets extracted from multiple sources, producing **Excel reports** and a concise **PowerPoint summary**.

---

## ğŸ§­ Project Overview
This project implements a **data quality assurance pipeline** for financial data. It combines **rule-based checks** with **LLM-powered contextual analysis** to highlight anomalies and prioritize review.  

Key quality measures implemented:
- **Completeness** â€“ Check for missing required fields  
- **Correctness** â€“ Validate numeric fields and fiscal period formats  
- **Consistency** â€“ Identify unusual year-over-year revenue spikes  
- **Uniqueness** â€“ Detect duplicate records per provider & year  
- **LLM Plausibility** â€“ Use Groq API (primary), fallback Gemini API, and mock fallback to flag suspicious values  

The pipeline outputs:
- A **flagged Excel file** with risk scores  
- A **PowerPoint summary deck**  
- Console logs showing LLM fallback decisions  

---

## ğŸ“ Project Structure
```text
â”œâ”€â”€ config/                  # Config files & settings
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Input Excel files
â”‚   â””â”€â”€ processed/           # Output flagged files (gitignored)
â”œâ”€â”€ src/                     # Production-grade Python scripts
â”‚   â”œâ”€â”€ analysis.py          # Peer/LLM analysis
â”‚   â”œâ”€â”€ data_preparation.py  # Cleaning & transformations
â”‚   â”œâ”€â”€ llm_utils.py         # LLM API calls & parsing
â”‚   â””â”€â”€ reporting.py         # Excel outputs
â”œâ”€â”€ notebooks/               # Exploratory Jupyter notebooks (3 stages)
â”œâ”€â”€ tests/                   # Unit tests (pytest)
â”œâ”€â”€ presentation/            # PowerPoint deliverable
â”œâ”€â”€ reports/                 # Automated report output
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## ğŸš€ Quickstart
1. Clone the repo
git clone https://github.com/YOUR_USERNAME/data-quality-casestudy.git
cd data-quality-casestudy
2. Create environment & install dependencies
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
3. Run the pipeline
python src/main.py

Output:
data/processed/flagged_output.xlsx â†’ Flagged dataset with risk scores
presentation/data_quality_summary.pptx â†’ Auto-generated PowerPoint

## âš™ï¸ LLM Integration
Primary: Groq API

Fallback 1: Gemini API

Fallback 2: Mock responses (ensures output is always generated)

Only the top 3 most volatile companies are analyzed with LLM for efficient resource management.

## ğŸ§ª Testing
Run all unit tests:

pytest
Over 25+ tests cover rule-based checks, LLM utilities, reporting, and full integration.

## ğŸ“Š Results
Automated detection of missing values, duplicates, and revenue anomalies

AI-assisted peer/contextual analysis for plausibility checks

Unified Excel + PowerPoint reporting for decision-making


## ğŸ¯ Next Steps
Add peer/industry benchmarks to strengthen anomaly detection

Build an active learning loop with analyst feedback for LLM refinement

Orchestrate with Airflow/dbt for scalable production deployment

## ğŸ§‘â€ğŸ’» Author Uchechukwu Obi 
[www.linkedin.com/in/uchechukwu-obi]

